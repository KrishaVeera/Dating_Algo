{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392b3be0-8814-43a5-bb6a-1a2f09fff3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ca9a08-bd1b-4e91-bc3f-10cd74730df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (59946, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\veera\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY user 1234 | age 31 | m straight | palo alto, california\n",
      "------------------------------------------------------------------------------------------\n",
      "hello! thanks for stopping by! i hope you enjoy yourself!  i am extremely financially responsible and nice! need a new kidney? i'll give you mine! if the doctor won't let us do that, i'll just buy you a new one! no expense is too much for you!  i definitely have skinny genes! rea...\n",
      "\n",
      "=== Matches ===\n",
      "\n",
      "user 44713 | age 23 | m straight | hayward, california | score=0.594\n",
      "hey my name is jacob i'm a die hard raider! lol i work as a massage therapist at chiropractic offices and my personal clients i do some personal tranning generally weight loss, nutrition, and hypertrophy. i'm currently attending ohlone college working on a physical therapy assist...\n",
      "------------------------------------------------------------------------------------------\n",
      "user 10612 | age 28 | m gay | san francisco, california | score=0.564\n",
      "high energy goofy nerd-jock-goofball type here. often compared to stifler from american pie. im always cracking a joke on someone or something and im a guaranteed good time. i am very easy to get along with once you get to know me. sometimes the high energy may come off like bull...\n",
      "------------------------------------------------------------------------------------------\n",
      "user 30903 | age 22 | m straight | novato, california | score=0.560\n",
      "first off, i hate the \"body type\" thing in the details thing bcz there is no in between for jacked and a little extra. i would call myself bulky or buff, or giant maybe. you should like big guys if you think you're interested in me. 6'4\" and 255 lbs. just saying. working on getti...\n",
      "------------------------------------------------------------------------------------------\n",
      "user 31197 | age 20 | f straight | berkeley, california | score=0.559\n",
      "i like to run, lift, dance, box, practice wushu, and olympic lift. i'm a carefree spirit that believes in having fun and enjoying every moment. i fell in love with guatemala summer '11 and went back again december '11. i plan on going back once or twice a year from here on out. n...\n",
      "------------------------------------------------------------------------------------------\n",
      "user 23695 | age 21 | m straight | san francisco, california | score=0.559\n",
      "oh i suck at these things. uhm. i'm 21 years old living in the best city in the world, san franfuckingcisco. i'm a super easy going person, i try my best to get along with everyone. i'm kind of reserved at first, but once the ice is broken, the fun begins. i hate drama with peopl...\n",
      "------------------------------------------------------------------------------------------\n",
      "coords in df: True True\n",
      "                          location        lat         lon\n",
      "0  south san francisco, california  37.653540 -122.416866\n",
      "1              oakland, california  37.804456 -122.271356\n",
      "2        san francisco, california  37.779259 -122.419329\n",
      "3             berkeley, california  37.870839 -122.272863\n",
      "4        san francisco, california  37.779259 -122.419329\n",
      "coords in tmp: True True\n",
      "   user_id        lat         lon\n",
      "0    44713  37.668821 -122.080796\n",
      "1    10612  37.779259 -122.419329\n",
      "2    30903  38.106198 -122.568119\n",
      "3    31197  37.870839 -122.272863\n",
      "4    23695  37.779259 -122.419329\n",
      "Base size: 7000\n",
      "Unfiltered: 7000 | After location filter (≤50 km): 6044\n",
      "Diet| before: 7000 → after: 6223\n",
      "Drinks | before: 7000 → after: 7000 (strict=False)\n",
      "Smokes | before: 7000 → after: 6731 (strict=False)\n",
      "Drugs  | before: 7000 → after: 6152 (strict=True)\n",
      "{'base': 7000, 'diet_only': 6223, 'drinks_only': 7000, 'smokes_only': 6731, 'drugs_only': 6152}\n",
      "Start pool: 5000 (max_candidates=5000)\n",
      "After orientation: 2023\n",
      "Unfiltered: 2023 | After location filter (≤50 km): 1717\n",
      "After location (≤50 km): 1717\n",
      "After age rule: 1342\n",
      "Diet| before: 1342 → after: 1152\n",
      "After diet: 1152\n",
      "Drinks | before: 1152 → after: 1152 (strict=False)\n",
      "After drinks (strict=False): 1152\n",
      "Smokes | before: 1152 → after: 1117 (strict=False)\n",
      "After smokes (strict=False): 1117\n",
      "Drugs  | before: 1117 → after: 1008 (strict=True)\n",
      "After drugs (strict=True): 1008\n",
      "Start pool: 5000 (max_candidates=5000)\n",
      "After orientation: 2023\n",
      "Unfiltered: 2023 | After location filter (≤50 km): 1717\n",
      "After location (≤50 km): 1717\n",
      "After age rule: 1342\n",
      "Diet| before: 1342 → after: 1152\n",
      "After diet: 1152\n",
      "Drinks | before: 1152 → after: 1152 (strict=False)\n",
      "After drinks (strict=False): 1152\n",
      "Smokes | before: 1152 → after: 1117 (strict=False)\n",
      "After smokes (strict=False): 1117\n",
      "Drugs  | before: 1117 → after: 1008 (strict=True)\n",
      "After drugs (strict=True): 1008\n",
      "df shape: (59946, 39)\n",
      "have get_matches? True\n"
     ]
    }
   ],
   "source": [
    "# Load your base notebook (embeddings, df, helpers)\n",
    "LIGHT_IMPORT = True\n",
    "%run -i \"Calc_Embeddings_Model Training.ipynb\"\n",
    "\n",
    "# quick sanity\n",
    "print(\"df shape:\", df.shape if 'df' in globals() else 'df missing')\n",
    "print(\"have get_matches?\", 'get_matches' in globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5546281e-19c9-40e6-a41b-dd4e53e2de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUPID_TOP_K   = 100\n",
    "CUPID_POOL_K  = 500\n",
    "CUPID_MAX_KM  = 45\n",
    "\n",
    "def cupid_candidate_pool(user_id: int,pool_k: int = CUPID_POOL_K,max_km: float = CUPID_MAX_KM) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the candidate pool using only hard gates:\n",
    "      - orientation/sex as the user specifies (inside get_matches)\n",
    "      - age range\n",
    "      - location radius\n",
    "    NOTE: No lifestyle gating here. We'll handle lifestyle softly during scoring.\n",
    "    \"\"\"\n",
    "    cands = get_matches(user_id=user_id, k=pool_k,use_orientation=True,use_location=True, max_km=max_km,use_age=True,\n",
    "        # all lifestyle OFF here -> soft handling later\n",
    "        use_diet=False, use_drinks=False, use_smokes=False, use_drugs=False,\n",
    "        drinks_strict=False, smokes_strict=False, drugs_strict=False,\n",
    "        allow_missing=True).copy()\n",
    "\n",
    "    # ensure a minimal set of columns is present (keep others if they exist)\n",
    "    base_cols = [\"user_id\", \"age\", \"sex\", \"orientation\", \"location\"]\n",
    "    for col in base_cols:\n",
    "        if col not in cands.columns:\n",
    "            cands[col] = np.nan\n",
    "\n",
    "    # return with base cols first, then any extra columns that came along\n",
    "    ordered = base_cols + [c for c in cands.columns if c not in base_cols]\n",
    "    return cands[ordered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a330446-04ab-47aa-9f5a-e2b526fd7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sets a few simple knobs (CUPID_TOP_K, CUPID_POOL_K, CUPID_MAX_KM).\n",
    "defines cupid_candidate_pool(...), which calls your get_matches with only hard gates (orientation, age, location). \n",
    "lifestyle is intentionally left out here, it will be soft later in the scoring step.\n",
    "runs a quick smoke test so you can see the pool size and first 10 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf2db9f1-1aff-42ee-ad56-4862ad9039d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start pool: 5000 (max_candidates=5000)\n",
      "After orientation: 2005\n",
      "Unfiltered: 2005 | After location filter (≤45 km): 1941\n",
      "After location (≤45 km): 1941\n",
      "After age rule: 1478\n",
      "pool size: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>location</th>\n",
       "      <th>text_sim</th>\n",
       "      <th>diet_c</th>\n",
       "      <th>drinks_c</th>\n",
       "      <th>smokes_c</th>\n",
       "      <th>drugs_c</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35029</td>\n",
       "      <td>33</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>0.690010</td>\n",
       "      <td>omnivore</td>\n",
       "      <td>heavy</td>\n",
       "      <td>heavy</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>37.779259</td>\n",
       "      <td>-122.419329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28566</td>\n",
       "      <td>30</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>0.682167</td>\n",
       "      <td>omnivore</td>\n",
       "      <td>light</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>37.779259</td>\n",
       "      <td>-122.419329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>49783</td>\n",
       "      <td>42</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>0.681057</td>\n",
       "      <td>omnivore</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>37.804456</td>\n",
       "      <td>-122.271356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>58244</td>\n",
       "      <td>48</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>moraga, california</td>\n",
       "      <td>0.672608</td>\n",
       "      <td></td>\n",
       "      <td>light</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>37.834897</td>\n",
       "      <td>-122.128830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20571</td>\n",
       "      <td>37</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san mateo, california</td>\n",
       "      <td>0.668853</td>\n",
       "      <td>other</td>\n",
       "      <td>light</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>37.496904</td>\n",
       "      <td>-122.333057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>6273</td>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>0.572045</td>\n",
       "      <td></td>\n",
       "      <td>light</td>\n",
       "      <td>light</td>\n",
       "      <td>none</td>\n",
       "      <td>37.779259</td>\n",
       "      <td>-122.419329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>29951</td>\n",
       "      <td>38</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san mateo, california</td>\n",
       "      <td>0.572012</td>\n",
       "      <td>omnivore</td>\n",
       "      <td>light</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>37.496904</td>\n",
       "      <td>-122.333057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>21686</td>\n",
       "      <td>63</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san rafael, california</td>\n",
       "      <td>0.571808</td>\n",
       "      <td>omnivore</td>\n",
       "      <td>heavy</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>37.974779</td>\n",
       "      <td>-122.531669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>4346</td>\n",
       "      <td>30</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>0.571759</td>\n",
       "      <td>omnivore</td>\n",
       "      <td>heavy</td>\n",
       "      <td>none</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>37.779259</td>\n",
       "      <td>-122.419329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>26068</td>\n",
       "      <td>42</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>daly city, california</td>\n",
       "      <td>0.571591</td>\n",
       "      <td></td>\n",
       "      <td>light</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "      <td>37.690483</td>\n",
       "      <td>-122.472670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  age sex orientation                   location  text_sim  \\\n",
       "5       35029   33   m    straight  san francisco, california  0.690010   \n",
       "11      28566   30   m    straight  san francisco, california  0.682167   \n",
       "13      49783   42   m    straight        oakland, california  0.681057   \n",
       "21      58244   48   m    straight         moraga, california  0.672608   \n",
       "23      20571   37   m    straight      san mateo, california  0.668853   \n",
       "...       ...  ...  ..         ...                        ...       ...   \n",
       "1769     6273   32   m    straight  san francisco, california  0.572045   \n",
       "1772    29951   38   m    straight      san mateo, california  0.572012   \n",
       "1779    21686   63   m    straight     san rafael, california  0.571808   \n",
       "1783     4346   30   m    straight  san francisco, california  0.571759   \n",
       "1790    26068   42   m    straight      daly city, california  0.571591   \n",
       "\n",
       "        diet_c drinks_c smokes_c    drugs_c        lat         lon  \n",
       "5     omnivore    heavy    heavy  sometimes  37.779259 -122.419329  \n",
       "11    omnivore    light     none       none  37.779259 -122.419329  \n",
       "13    omnivore     none     none       none  37.804456 -122.271356  \n",
       "21                light     none       none  37.834897 -122.128830  \n",
       "23       other    light     none       none  37.496904 -122.333057  \n",
       "...        ...      ...      ...        ...        ...         ...  \n",
       "1769              light    light       none  37.779259 -122.419329  \n",
       "1772  omnivore    light     none       none  37.496904 -122.333057  \n",
       "1779  omnivore    heavy     none       none  37.974779 -122.531669  \n",
       "1783  omnivore    heavy     none  sometimes  37.779259 -122.419329  \n",
       "1790              light     none             37.690483 -122.472670  \n",
       "\n",
       "[500 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = 15\n",
    "pool = cupid_candidate_pool(user_id=u)\n",
    "print(\"pool size:\", len(pool))\n",
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200cb5cf-cb9d-4aa2-993f-04d01bf27aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base compatibility (text/age/lifestyle/location)\n",
    "# Uses your compute_component_scores to get component columns, then blends them into a single base_score (no freshness/explore yet).\n",
    "\n",
    "# weights for the base\n",
    "CUPID_W = {\"text\": 0.60, \"age\": 0.10, \"life\": 0.15, \"loc\": 0.15}\n",
    "\n",
    "def _ensure_text_sim(cands: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    make sure text_sim is numeric and clipped to [0,1].\n",
    "    \"\"\"\n",
    "    c = cands.copy()\n",
    "    c[\"text_sim\"] = pd.to_numeric(c.get(\"text_sim\", 0.0), errors=\"coerce\").fillna(0.0).clip(0, 1)\n",
    "    return c\n",
    "\n",
    "def cupid_base_compat(user_id: int,pool_k: int = CUPID_POOL_K,max_km: float = CUPID_MAX_KM,\n",
    "                      weights: dict = CUPID_W) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Build hard-gated pool (orientation/age/location)\n",
    "    2) Compute component scores (text_sim, age_score, lifestyle_score, loc_score)\n",
    "    3) Blend into base_score = 0.60*text + 0.10*age + 0.15*life + 0.15*loc\n",
    "    Returns a dataframe sorted by base_score (desc).\n",
    "    \"\"\"\n",
    "    # (1) pool\n",
    "    pool = cupid_candidate_pool(user_id=user_id, pool_k=pool_k, max_km=max_km)\n",
    "\n",
    "    # (2) component scores (lifestyle kept soft here)\n",
    "    c = compute_component_scores(user_id=user_id, cands=pool, max_km=max_km,\n",
    "        drinks_strict=False, smokes_strict=False, drugs_strict=False, allow_missing=True)\n",
    "    c = _ensure_text_sim(c)\n",
    "\n",
    "    # make sure required columns exist\n",
    "    for col in [\"age_score\", \"lifestyle_score\", \"loc_score\"]:\n",
    "        if col not in c.columns:\n",
    "            c[col] = 0.0\n",
    "\n",
    "    # (3) weighted blend\n",
    "    w = weights\n",
    "    c[\"base_score\"] = (w[\"text\"] * c[\"text_sim\"] +w[\"age\"]  * c[\"age_score\"] +w[\"life\"] * c[\"lifestyle_score\"] +\n",
    "        w[\"loc\"]  * c[\"loc_score\"])\n",
    "\n",
    "    need = [\"user_id\", \"base_score\", \"text_sim\", \"age_score\", \"lifestyle_score\", \"loc_score\",\n",
    "            \"age\", \"sex\", \"orientation\", \"location\"]\n",
    "    for col in need:\n",
    "        if col not in c.columns:\n",
    "            c[col] = np.nan\n",
    "\n",
    "    return c[need].sort_values(\"base_score\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ec35f40-18b3-452a-946e-ed7e5ffd73ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start pool: 5000 (max_candidates=5000)\n",
      "After orientation: 2005\n",
      "Unfiltered: 2005 | After location filter (≤50 km): 1990\n",
      "After location (≤50 km): 1990\n",
      "After age rule: 1511\n",
      "rows: 500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>base_score</th>\n",
       "      <th>text_sim</th>\n",
       "      <th>age_score</th>\n",
       "      <th>lifestyle_score</th>\n",
       "      <th>loc_score</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44725</td>\n",
       "      <td>0.822358</td>\n",
       "      <td>0.703931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>alameda, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28566</td>\n",
       "      <td>0.809300</td>\n",
       "      <td>0.682167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49783</td>\n",
       "      <td>0.808634</td>\n",
       "      <td>0.681057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>oakland, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58244</td>\n",
       "      <td>0.803565</td>\n",
       "      <td>0.672608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>moraga, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31789</td>\n",
       "      <td>0.803546</td>\n",
       "      <td>0.672577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>alameda, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>37355</td>\n",
       "      <td>0.647360</td>\n",
       "      <td>0.578934</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>52368</td>\n",
       "      <td>0.645354</td>\n",
       "      <td>0.575591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>32003</td>\n",
       "      <td>0.643842</td>\n",
       "      <td>0.573070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>44076</td>\n",
       "      <td>0.623434</td>\n",
       "      <td>0.622389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>20878</td>\n",
       "      <td>0.600668</td>\n",
       "      <td>0.584447</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>berkeley, california</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  base_score  text_sim  age_score  lifestyle_score  loc_score  \\\n",
       "0      44725    0.822358  0.703931        1.0         1.000000        1.0   \n",
       "1      28566    0.809300  0.682167        1.0         1.000000        1.0   \n",
       "2      49783    0.808634  0.681057        1.0         1.000000        1.0   \n",
       "3      58244    0.803565  0.672608        1.0         1.000000        1.0   \n",
       "4      31789    0.803546  0.672577        1.0         1.000000        1.0   \n",
       "..       ...         ...       ...        ...              ...        ...   \n",
       "495    37355    0.647360  0.578934        1.0         0.333333        1.0   \n",
       "496    52368    0.645354  0.575591        1.0         0.333333        1.0   \n",
       "497    32003    0.643842  0.573070        1.0         0.333333        1.0   \n",
       "498    44076    0.623434  0.622389        1.0         0.000000        1.0   \n",
       "499    20878    0.600668  0.584447        1.0         0.000000        1.0   \n",
       "\n",
       "     age sex orientation                   location  \n",
       "0     54   m    straight        alameda, california  \n",
       "1     30   m    straight  san francisco, california  \n",
       "2     42   m    straight        oakland, california  \n",
       "3     48   m    straight         moraga, california  \n",
       "4     46   m    straight        alameda, california  \n",
       "..   ...  ..         ...                        ...  \n",
       "495   49   m    straight  san francisco, california  \n",
       "496   27   m    straight  san francisco, california  \n",
       "497   35   m    straight  san francisco, california  \n",
       "498   33   m    straight  san francisco, california  \n",
       "499   55   m    straight       berkeley, california  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = 15\n",
    "base = cupid_base_compat(user_id=u)\n",
    "print(\"rows:\", len(base))\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc15db5c-676f-43c0-8c06-a27eb81de5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built recency_norm. Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>base_score</th>\n",
       "      <th>recency_norm</th>\n",
       "      <th>cupid_score_fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44725</td>\n",
       "      <td>0.822358</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.922088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28566</td>\n",
       "      <td>0.809300</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.909030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49783</td>\n",
       "      <td>0.808634</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.908364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58244</td>\n",
       "      <td>0.803565</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.903295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31789</td>\n",
       "      <td>0.803546</td>\n",
       "      <td>0.818919</td>\n",
       "      <td>0.885438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>37355</td>\n",
       "      <td>0.647360</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.743036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>52368</td>\n",
       "      <td>0.645354</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.744544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>32003</td>\n",
       "      <td>0.643842</td>\n",
       "      <td>0.781081</td>\n",
       "      <td>0.721950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>44076</td>\n",
       "      <td>0.623434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>20878</td>\n",
       "      <td>0.600668</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.664182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  base_score  recency_norm  cupid_score_fresh\n",
       "0      44725    0.822358      0.997297           0.922088\n",
       "1      28566    0.809300      0.997297           0.909030\n",
       "2      49783    0.808634      0.997297           0.908364\n",
       "3      58244    0.803565      0.997297           0.903295\n",
       "4      31789    0.803546      0.818919           0.885438\n",
       "..       ...         ...           ...                ...\n",
       "495    37355    0.647360      0.956757           0.743036\n",
       "496    52368    0.645354      0.991892           0.744544\n",
       "497    32003    0.643842      0.781081           0.721950\n",
       "498    44076    0.623434      1.000000           0.723434\n",
       "499    20878    0.600668      0.635135           0.664182\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freshness \n",
    "# - Format last_online to YYYY-MM-DD\n",
    "# - Build recency_norm ∈ [0,1] on the master df\n",
    "# - Add freshness to base_score → cupid_score_fresh\n",
    "\n",
    "CUPID_G_FRESH = 0.10  # weight for freshness\n",
    "\n",
    "# 1) Clean + parse dates on master df\n",
    "df[\"last_online_clean\"] = df[\"last_online\"].astype(str).str.slice(0, 10)  # YYYY-MM-DD\n",
    "df[\"last_online_dt\"] = pd.to_datetime(df[\"last_online_clean\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "# 2) Normalize to [0,1] over the dataset\n",
    "min_dt = df[\"last_online_dt\"].min()\n",
    "max_dt = df[\"last_online_dt\"].max()\n",
    "\n",
    "if pd.notna(min_dt) and pd.notna(max_dt) and max_dt > min_dt:\n",
    "    span_sec = (max_dt - min_dt).total_seconds()\n",
    "    df[\"recency_norm\"] = ((df[\"last_online_dt\"] - min_dt).dt.total_seconds() / span_sec).fillna(0.0)\n",
    "else:\n",
    "    # if all dates are the same or missing, set to 0.0\n",
    "    df[\"recency_norm\"] = 0.0\n",
    "\n",
    "# 3) Merge into base and add freshness bump\n",
    "fresh = base.merge(df[[\"user_id\", \"recency_norm\"]], on=\"user_id\", how=\"left\")\n",
    "fresh[\"recency_norm\"] = fresh[\"recency_norm\"].fillna(0.0).clip(0, 1)\n",
    "fresh[\"cupid_score_fresh\"] = fresh[\"base_score\"] + CUPID_G_FRESH * fresh[\"recency_norm\"]\n",
    "\n",
    "print(\"Built recency_norm. Preview:\")\n",
    "fresh[[\"user_id\",\"base_score\",\"recency_norm\",\"cupid_score_fresh\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71dd5b1e-b64d-4842-b905-1519c038c60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic explore+pop added. Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recency_norm</th>\n",
       "      <th>text_sim</th>\n",
       "      <th>lifestyle_score</th>\n",
       "      <th>schedule_strength</th>\n",
       "      <th>right_swipe_rate</th>\n",
       "      <th>ucb_bonus</th>\n",
       "      <th>pop_penalty</th>\n",
       "      <th>cupid_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44725</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.703931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.145993</td>\n",
       "      <td>0.813595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28566</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.682167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.718020</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.143604</td>\n",
       "      <td>0.802926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49783</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.681057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.663848</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.132770</td>\n",
       "      <td>0.813094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58244</td>\n",
       "      <td>0.997297</td>\n",
       "      <td>0.672608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.645482</td>\n",
       "      <td>0.038730</td>\n",
       "      <td>0.129096</td>\n",
       "      <td>0.812928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31789</td>\n",
       "      <td>0.818919</td>\n",
       "      <td>0.672577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.676531</td>\n",
       "      <td>0.041603</td>\n",
       "      <td>0.135306</td>\n",
       "      <td>0.791734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>37355</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.578934</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>0.556998</td>\n",
       "      <td>0.040089</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.671726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>52368</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.575591</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15</td>\n",
       "      <td>0.519882</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.103976</td>\n",
       "      <td>0.678067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>32003</td>\n",
       "      <td>0.781081</td>\n",
       "      <td>0.573070</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>11</td>\n",
       "      <td>0.553931</td>\n",
       "      <td>0.043301</td>\n",
       "      <td>0.110786</td>\n",
       "      <td>0.654465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>44076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.505092</td>\n",
       "      <td>0.038730</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>0.661145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>20878</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.584447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.477092</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>0.616198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  recency_norm  text_sim  lifestyle_score  schedule_strength  \\\n",
       "0      44725      0.997297  0.703931         1.000000                 15   \n",
       "1      28566      0.997297  0.682167         1.000000                 15   \n",
       "2      49783      0.997297  0.681057         1.000000                 15   \n",
       "3      58244      0.997297  0.672608         1.000000                 14   \n",
       "4      31789      0.818919  0.672577         1.000000                 12   \n",
       "..       ...           ...       ...              ...                ...   \n",
       "495    37355      0.956757  0.578934         0.333333                 13   \n",
       "496    52368      0.991892  0.575591         0.333333                 15   \n",
       "497    32003      0.781081  0.573070         0.333333                 11   \n",
       "498    44076      1.000000  0.622389         0.000000                 14   \n",
       "499    20878      0.635135  0.584447         0.000000                  9   \n",
       "\n",
       "     right_swipe_rate  ucb_bonus  pop_penalty  cupid_base  \n",
       "0            0.729964   0.037500     0.145993    0.813595  \n",
       "1            0.718020   0.037500     0.143604    0.802926  \n",
       "2            0.663848   0.037500     0.132770    0.813094  \n",
       "3            0.645482   0.038730     0.129096    0.812928  \n",
       "4            0.676531   0.041603     0.135306    0.791734  \n",
       "..                ...        ...          ...         ...  \n",
       "495          0.556998   0.040089     0.111400    0.671726  \n",
       "496          0.519882   0.037500     0.103976    0.678067  \n",
       "497          0.553931   0.043301     0.110786    0.654465  \n",
       "498          0.505092   0.038730     0.101018    0.661145  \n",
       "499          0.477092   0.047434     0.095418    0.616198  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Synthesize encounters & popularity, then compute cupid_base\n",
    "# - Reproducible synthetic schedule_strength and right_swipe_rate\n",
    "# - Adds UCB bonus and popularity penalty, producing `cupid_base`\n",
    "\n",
    "CUPID_ALPHA_UCB = 0.15   # exploration strength\n",
    "CUPID_BETA_POP  = 0.20   # popularity penalty\n",
    "CUPID_SYN_SEED  = 7      # reproducible\n",
    "\n",
    "rng = np.random.default_rng(CUPID_SYN_SEED)\n",
    "\n",
    "def cupid_add_explore_pop_synth(fresh_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build synthetic:\n",
    "      - schedule_strength: higher if more recent activity, with noise (0..~20)\n",
    "      - right_swipe_rate: function of text_sim + lifestyle_score, with tiny noise (0..1)\n",
    "    Then compute:\n",
    "      - ucb_bonus = α / sqrt(1 + schedule_strength)\n",
    "      - pop_penalty = β * right_swipe_rate\n",
    "      - cupid_base  = cupid_score_fresh + ucb_bonus - pop_penalty\n",
    "    \"\"\"\n",
    "    out = fresh_df.copy()\n",
    "\n",
    "    # Make sure needed columns exist\n",
    "    for col in [\"recency_norm\", \"text_sim\", \"lifestyle_score\", \"cupid_score_fresh\"]:\n",
    "        if col not in out.columns:\n",
    "            out[col] = 0.0\n",
    "\n",
    "    # Synthetic encounters: more recent users tend to have more encounters\n",
    "    # scale to ~0..20 with some randomness\n",
    "    base_enc = 14 * out[\"recency_norm\"] + 2 * rng.random(len(out))\n",
    "    out[\"schedule_strength\"] = np.floor(np.clip(base_enc, 0, None)).astype(int)\n",
    "\n",
    "    # Synthetic popularity: driven by text & lifestyle; small noise\n",
    "    rrate = (0.10 + 0.65 * out[\"text_sim\"] + 0.15 * out[\"lifestyle_score\"] + 0.03 * rng.standard_normal(len(out)))\n",
    "    out[\"right_swipe_rate\"] = np.clip(rrate, 0.0, 1.0)\n",
    "\n",
    "    # Exploration bonus (bigger for low-encounter users)\n",
    "    out[\"ucb_bonus\"]   = CUPID_ALPHA_UCB / np.sqrt(1.0 + out[\"schedule_strength\"])\n",
    "    # Popularity penalty (downweight very over-exposed profiles)\n",
    "    out[\"pop_penalty\"] = CUPID_BETA_POP * out[\"right_swipe_rate\"]\n",
    "\n",
    "    # Final per-candidate pre-slate score\n",
    "    out[\"cupid_base\"]  = out[\"cupid_score_fresh\"] + out[\"ucb_bonus\"] - out[\"pop_penalty\"]\n",
    "\n",
    "    # peek\n",
    "    print(\"Synthetic explore+pop added. Preview:\")\n",
    "    display(out[[\"user_id\",\"recency_norm\",\"text_sim\",\"lifestyle_score\",\"schedule_strength\",\"right_swipe_rate\",\n",
    "                 \"ucb_bonus\",\"pop_penalty\",\"cupid_base\"]].head(8))\n",
    "    return out\n",
    "\n",
    "# %% [markdown]\n",
    "# CUPID — Cell 3b (alt): Synthesize encounters & popularity, then compute cupid_base\n",
    "# - No Elo code required\n",
    "# - Reproducible synthetic schedule_strength and right_swipe_rate\n",
    "# - Adds UCB bonus and popularity penalty, producing `cupid_base`\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CUPID_ALPHA_UCB = 0.15   # exploration strength\n",
    "CUPID_BETA_POP  = 0.20   # popularity penalty\n",
    "CUPID_SYN_SEED  = 7      # reproducible\n",
    "\n",
    "rng = np.random.default_rng(CUPID_SYN_SEED)\n",
    "\n",
    "def cupid_add_explore_pop_synth(fresh_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build synthetic:\n",
    "      - schedule_strength: higher if more recent activity, with noise (0..~20)\n",
    "      - right_swipe_rate: function of text_sim + lifestyle_score, with tiny noise (0..1)\n",
    "    Then compute:\n",
    "      - ucb_bonus = α / sqrt(1 + schedule_strength)\n",
    "      - pop_penalty = β * right_swipe_rate\n",
    "      - cupid_base  = cupid_score_fresh + ucb_bonus - pop_penalty\n",
    "    \"\"\"\n",
    "    out = fresh_df.copy()\n",
    "\n",
    "    # Make sure needed columns exist\n",
    "    for col in [\"recency_norm\", \"text_sim\", \"lifestyle_score\", \"cupid_score_fresh\"]:\n",
    "        if col not in out.columns:\n",
    "            out[col] = 0.0\n",
    "\n",
    "    # Synthetic encounters: more recent users tend to have more encounters\n",
    "    # scale to ~0..20 with some randomness\n",
    "    base_enc = 14 * out[\"recency_norm\"] + 2 * rng.random(len(out))\n",
    "    out[\"schedule_strength\"] = np.floor(np.clip(base_enc, 0, None)).astype(int)\n",
    "\n",
    "    # Synthetic popularity: driven by text & lifestyle; small noise\n",
    "    rrate = (\n",
    "        0.10 + 0.65 * out[\"text_sim\"] + 0.15 * out[\"lifestyle_score\"] + 0.03 * rng.standard_normal(len(out))\n",
    "    )\n",
    "    out[\"right_swipe_rate\"] = np.clip(rrate, 0.0, 1.0)\n",
    "\n",
    "    # Exploration bonus (bigger for low-encounter users)\n",
    "    out[\"ucb_bonus\"]   = CUPID_ALPHA_UCB / np.sqrt(1.0 + out[\"schedule_strength\"])\n",
    "    # Popularity penalty (downweight very over-exposed profiles)\n",
    "    out[\"pop_penalty\"] = CUPID_BETA_POP * out[\"right_swipe_rate\"]\n",
    "\n",
    "    # Final per-candidate pre-slate score\n",
    "    out[\"cupid_base\"]  = out[\"cupid_score_fresh\"] + out[\"ucb_bonus\"] - out[\"pop_penalty\"]\n",
    "\n",
    "    # peek\n",
    "    print(\"Synthetic explore+pop added. Preview:\")\n",
    "    display(out[[\"user_id\",\"recency_norm\",\"text_sim\",\"lifestyle_score\",\n",
    "                 \"schedule_strength\",\"right_swipe_rate\",\n",
    "                 \"ucb_bonus\",\"pop_penalty\",\"cupid_base\"]])\n",
    "    return out\n",
    "\n",
    "# --- test run it on current `fresh` ---\n",
    "scored = cupid_add_explore_pop_synth(fresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85e9e62b-1443-47d7-b506-634233f34cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword boost (log-scale) added. Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>kw_shared</th>\n",
       "      <th>kw_bonus</th>\n",
       "      <th>cupid_base</th>\n",
       "      <th>cupid_score_kw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813595</td>\n",
       "      <td>0.813595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28566</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.802926</td>\n",
       "      <td>0.802926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49783</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813094</td>\n",
       "      <td>0.813094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812928</td>\n",
       "      <td>0.812928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791734</td>\n",
       "      <td>0.791734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>37355</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671726</td>\n",
       "      <td>0.671726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>52368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678067</td>\n",
       "      <td>0.678067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>32003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654465</td>\n",
       "      <td>0.654465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>44076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.661145</td>\n",
       "      <td>0.661145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>20878</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616198</td>\n",
       "      <td>0.616198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  kw_shared  kw_bonus  cupid_base  cupid_score_kw\n",
       "0      44725          0       0.0    0.813595        0.813595\n",
       "1      28566          0       0.0    0.802926        0.802926\n",
       "2      49783          0       0.0    0.813094        0.813094\n",
       "3      58244          0       0.0    0.812928        0.812928\n",
       "4      31789          0       0.0    0.791734        0.791734\n",
       "..       ...        ...       ...         ...             ...\n",
       "495    37355          0       0.0    0.671726        0.671726\n",
       "496    52368          0       0.0    0.678067        0.678067\n",
       "497    32003          0       0.0    0.654465        0.654465\n",
       "498    44076          0       0.0    0.661145        0.661145\n",
       "499    20878          0       0.0    0.616198        0.616198\n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Reciprocal keyword boost (shared interests) — log-scale bonus\n",
    "# - Extract keyword sets from bio_text (user & candidates)\n",
    "# - Add diminishing-returns bonus via log1p(shared)\n",
    "# - Output columns: kw_shared, kw_bonus, cupid_score_kw, cupid_pre_slate\n",
    "\n",
    "import re\n",
    "\n",
    "# Small, interpretable keyword lexicon (extend anytime)\n",
    "CUPID_KEYWORDS = {\"hiking\",\"hike\",\"run\",\"running\",\"walk\",\"walking\",\"gym\",\"fitness\",\"yoga\",\"climb\",\"biking\",\n",
    "                  \"cycling\",\"swim\",\"travel\",\"trip\",\"explore\",\"roadtrip\",\"camp\",\"music\",\"concert\",\"festival\",\n",
    "                  \"dj\",\"guitar\",\"piano\",\"sing\",\"movie\",\"movies\",\"film\",\"netflix\",\"series\",\"tv\",\"anime\",\n",
    "                  \"art\",\"museum\",\"gallery\",\"paint\",\"painting\",\"draw\",\"photography\",\"food\",\"cook\",\"cooking\",\n",
    "                  \"bake\",\"coffee\",\"brunch\",\"restaurants\",\"reading\",\"books\",\"book\",\"boardgames\",\"games\",\"gaming\",\n",
    "                  \"dog\",\"dogs\",\"cat\",\"cats\",\"pets\"}\n",
    " \n",
    "CUPID_DELTA_KW = 0.03  # base factor for keyword bonus (tunable)\n",
    "\n",
    "def _kw_set(text: str) -> set:\n",
    "    \"\"\"Lowercase, tokenize, keep only words in CUPID_KEYWORDS.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return set()\n",
    "    tokens = re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    return {t for t in tokens if t in CUPID_KEYWORDS}\n",
    "\n",
    "def cupid_add_keywords_log(base_df: pd.DataFrame, user_id: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add keyword overlap bonus:\n",
    "      kw_bonus = δ * log(1 + #shared_keywords)\n",
    "    Produces: kw_shared, kw_bonus, cupid_score_kw, cupid_pre_slate\n",
    "    \"\"\"\n",
    "    out = base_df.copy()\n",
    "\n",
    "    # Build a fast lookup for bios\n",
    "    bio_map = df.set_index(\"user_id\")[\"bio_text\"].to_dict()\n",
    "\n",
    "    # User keyword set\n",
    "    user_bio = bio_map.get(int(user_id), \"\")\n",
    "    user_kw  = _kw_set(user_bio)\n",
    "\n",
    "    # Overlap count per candidate\n",
    "    def _overlap(uid):\n",
    "        cand_bio = bio_map.get(int(uid), \"\")\n",
    "        return len(user_kw & _kw_set(cand_bio))\n",
    "\n",
    "    out[\"kw_shared\"] = out[\"user_id\"].astype(int).map(_overlap)\n",
    "\n",
    "    # Log-scale bonus: grows with shared interests but with diminishing returns\n",
    "    out[\"kw_bonus\"] = CUPID_DELTA_KW * np.log1p(out[\"kw_shared\"])\n",
    "\n",
    "    # Add into score\n",
    "    if \"cupid_base\" not in out.columns:\n",
    "        raise KeyError(\"cupid_add_keywords_log expects 'cupid_base' in the input dataframe.\")\n",
    "    out[\"cupid_score_kw\"] = out[\"cupid_base\"] + out[\"kw_bonus\"]\n",
    "\n",
    "    # Alias for next step (pre-slate score before fairness/diversity)\n",
    "    out[\"cupid_pre_slate\"] = out[\"cupid_score_kw\"]\n",
    "\n",
    "    print(\"Keyword boost (log-scale) added. Preview:\")\n",
    "    display(out[[\"user_id\",\"kw_shared\",\"kw_bonus\",\"cupid_base\",\"cupid_score_kw\"]])\n",
    "    return out\n",
    "\n",
    "scored_kw = cupid_add_keywords_log(scored, user_id=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68b79d1f-566f-4435-a90f-73e84dcd97c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cupid_pre_slate</th>\n",
       "      <th>div_penalty</th>\n",
       "      <th>cupid_final</th>\n",
       "      <th>kw_set</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>0.819688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.819688</td>\n",
       "      <td>{movie, music}</td>\n",
       "      <td>m</td>\n",
       "      <td>43</td>\n",
       "      <td>san mateo, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44725</td>\n",
       "      <td>0.813595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.813595</td>\n",
       "      <td>{travel, food}</td>\n",
       "      <td>m</td>\n",
       "      <td>54</td>\n",
       "      <td>alameda, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49783</td>\n",
       "      <td>0.813094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.813094</td>\n",
       "      <td>{coffee, walking, run}</td>\n",
       "      <td>m</td>\n",
       "      <td>42</td>\n",
       "      <td>oakland, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11636</td>\n",
       "      <td>0.799925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.799925</td>\n",
       "      <td>{books, hike, tv}</td>\n",
       "      <td>m</td>\n",
       "      <td>63</td>\n",
       "      <td>berkeley, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33493</td>\n",
       "      <td>0.796318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796318</td>\n",
       "      <td>{}</td>\n",
       "      <td>m</td>\n",
       "      <td>36</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>29371</td>\n",
       "      <td>0.792236</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.658902</td>\n",
       "      <td>{music, books, hiking, movies, reading, movie,...</td>\n",
       "      <td>m</td>\n",
       "      <td>31</td>\n",
       "      <td>vallejo, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33773</td>\n",
       "      <td>0.767608</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.658517</td>\n",
       "      <td>{travel, music, biking, dj, trip, movie, book,...</td>\n",
       "      <td>m</td>\n",
       "      <td>33</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>55125</td>\n",
       "      <td>0.784562</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.658246</td>\n",
       "      <td>{travel, music, food, books, netflix, tv, read...</td>\n",
       "      <td>m</td>\n",
       "      <td>33</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33399</td>\n",
       "      <td>0.758234</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.658234</td>\n",
       "      <td>{tv}</td>\n",
       "      <td>m</td>\n",
       "      <td>31</td>\n",
       "      <td>pacifica, california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>34591</td>\n",
       "      <td>0.758052</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.658052</td>\n",
       "      <td>{music, explore}</td>\n",
       "      <td>m</td>\n",
       "      <td>28</td>\n",
       "      <td>san francisco, california</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  cupid_pre_slate  div_penalty  cupid_final  \\\n",
       "0     20973         0.819688     0.000000     0.819688   \n",
       "1     44725         0.813595     0.000000     0.813595   \n",
       "2     49783         0.813094     0.000000     0.813094   \n",
       "3     11636         0.799925     0.000000     0.799925   \n",
       "4     33493         0.796318     0.000000     0.796318   \n",
       "..      ...              ...          ...          ...   \n",
       "95    29371         0.792236     0.133333     0.658902   \n",
       "96    33773         0.767608     0.109091     0.658517   \n",
       "97    55125         0.784562     0.126316     0.658246   \n",
       "98    33399         0.758234     0.100000     0.658234   \n",
       "99    34591         0.758052     0.100000     0.658052   \n",
       "\n",
       "                                               kw_set sex  age  \\\n",
       "0                                      {movie, music}   m   43   \n",
       "1                                      {travel, food}   m   54   \n",
       "2                              {coffee, walking, run}   m   42   \n",
       "3                                   {books, hike, tv}   m   63   \n",
       "4                                                  {}   m   36   \n",
       "..                                                ...  ..  ...   \n",
       "95  {music, books, hiking, movies, reading, movie,...   m   31   \n",
       "96  {travel, music, biking, dj, trip, movie, book,...   m   33   \n",
       "97  {travel, music, food, books, netflix, tv, read...   m   33   \n",
       "98                                               {tv}   m   31   \n",
       "99                                   {music, explore}   m   28   \n",
       "\n",
       "                     location  \n",
       "0       san mateo, california  \n",
       "1         alameda, california  \n",
       "2         oakland, california  \n",
       "3        berkeley, california  \n",
       "4   san francisco, california  \n",
       "..                        ...  \n",
       "95        vallejo, california  \n",
       "96  san francisco, california  \n",
       "97  san francisco, california  \n",
       "98       pacifica, california  \n",
       "99  san francisco, california  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In‑slate diversity (greedy with similarity penalty)\n",
    "# Input:  scored_kw  (must contain 'cupid_pre_slate'; will fetch bios from df)\n",
    "# Method:\n",
    "#   - Start from the highest 'cupid_pre_slate'\n",
    "#   - For each next pick, compute Jaccard similarity between each remaining\n",
    "#     candidate's keyword set and the sets already in the slate.\n",
    "#   - Apply penalty = λ * max_similarity_to_slate\n",
    "#   - Select argmax( score - penalty )\n",
    "# Output: 'cupid_final' with diagnostic columns.\n",
    "\n",
    "DIVERSITY_LAMBDA = 0.30  # λ — strength of the penalty (0.2–0.4 works well)\n",
    "\n",
    "def _kw_set(text: str, lexicon) -> set:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return set()\n",
    "    toks = re.findall(r\"[a-zA-Z]+\", text.lower())\n",
    "    return {t for t in toks if t in lexicon}\n",
    "\n",
    "def _jaccard(a: set, b: set) -> float:\n",
    "    if not a and not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def cupid_build_diverse_slate(pre_df: pd.DataFrame,k: int = CUPID_TOP_K,lexicon=CUPID_KEYWORDS,\n",
    "                              lam: float = DIVERSITY_LAMBDA) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Greedy diverse selection on 'cupid_pre_slate'.\n",
    "    Returns a DataFrame with columns:\n",
    "      ['user_id','cupid_pre_slate','div_penalty','cupid_final','kw_set','kw_shared']\n",
    "    \"\"\"\n",
    "    C = pre_df.copy()\n",
    "    if \"cupid_pre_slate\" not in C.columns:\n",
    "        raise KeyError(\"Expected 'cupid_pre_slate' in input dataframe (run keyword step first).\")\n",
    "\n",
    "    # Bring bios for keyword sets\n",
    "    if \"bio_text\" not in C.columns:\n",
    "        C = C.merge(df[[\"user_id\",\"bio_text\"]], on=\"user_id\", how=\"left\")\n",
    "\n",
    "    # Precompute keyword sets for each candidate\n",
    "    bio_map = C.set_index(\"user_id\")[\"bio_text\"].to_dict()\n",
    "    kw_map  = {int(uid): _kw_set(bio_map.get(int(uid), \"\"), lexicon) for uid in C[\"user_id\"].astype(int)}\n",
    "\n",
    "    # Work arrays\n",
    "    C = C.sort_values(\"cupid_pre_slate\", ascending=False).reset_index(drop=True)\n",
    "    taken_ids = []\n",
    "    taken_kw  = []\n",
    "\n",
    "    # For diagnostics\n",
    "    penalties = {}\n",
    "    final_scores = {}\n",
    "\n",
    "    for _ in range(min(k, len(C))):\n",
    "        best_idx, best_val, best_pen = None, -1e9, 0.0\n",
    "\n",
    "        for idx, row in C.iterrows():\n",
    "            uid = int(row[\"user_id\"])\n",
    "            if uid in taken_ids:\n",
    "                continue\n",
    "\n",
    "            # similarity penalty: compare to already chosen sets\n",
    "            K = kw_map.get(uid, set())\n",
    "            if taken_kw:\n",
    "                sim = max((_jaccard(K, T) for T in taken_kw), default=0.0)\n",
    "            else:\n",
    "                sim = 0.0\n",
    "            pen = lam * sim\n",
    "            val = float(row[\"cupid_pre_slate\"]) - pen\n",
    "\n",
    "            if val > best_val:\n",
    "                best_val, best_idx, best_pen = val, idx, pen\n",
    "\n",
    "        # take the best one\n",
    "        if best_idx is None:\n",
    "            break\n",
    "        chosen = C.loc[best_idx].copy()\n",
    "        uid = int(chosen[\"user_id\"])\n",
    "        taken_ids.append(uid)\n",
    "        taken_kw.append(kw_map.get(uid, set()))\n",
    "        penalties[uid] = best_pen\n",
    "        final_scores[uid] = best_val\n",
    "\n",
    "    # Build slate frame\n",
    "    slate = C[C[\"user_id\"].isin(taken_ids)].copy()\n",
    "    slate[\"div_penalty\"] = slate[\"user_id\"].map(penalties).fillna(0.0)\n",
    "    slate[\"cupid_final\"] = slate[\"user_id\"].map(final_scores)\n",
    "    # handy columns for display\n",
    "    slate[\"kw_set\"] = slate[\"user_id\"].map(kw_map)\n",
    "    slate = slate.sort_values(\"cupid_final\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    cols = [\"user_id\",\"cupid_pre_slate\",\"div_penalty\",\"cupid_final\",\"kw_set\",\"sex\",\"age\",\"location\"]\n",
    "    for c in cols:\n",
    "        if c not in slate.columns:\n",
    "            slate[c] = np.nan\n",
    "    return slate[cols]\n",
    "\n",
    "# --- build a diverse top-k from your current pre-slate ---\n",
    "diverse_slate = cupid_build_diverse_slate(scored_kw, k=100)\n",
    "diverse_slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ae24ca5-cab0-4295-8251-67c0cf8c9a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretty final table with shared interests & notes\n",
    "# Inputs: diverse_slate (from Cell 5b), df (master), u (target user_id)\n",
    "# Output: final_table (nice display)\n",
    "\n",
    "DISPLAY_SHARED_MAX = 4\n",
    "\n",
    "def user_kw_set(user_id: int) -> set:\n",
    "    bio = df.loc[df[\"user_id\"] == user_id, \"bio_text\"]\n",
    "    bio = str(bio.iloc[0]) if len(bio) else \"\"\n",
    "    toks = re.findall(r\"[a-zA-Z]+\", bio.lower())\n",
    "    return {t for t in toks if t in CUPID_KEYWORDS}\n",
    "\n",
    "def shared_kw_str(user_kw: set, cand_kw: set, limit: int = DISPLAY_SHARED_MAX) -> str:\n",
    "    shared = sorted(user_kw & (cand_kw or set()))\n",
    "    if not shared:\n",
    "        return \"\"\n",
    "    return \", \".join(shared[:limit]) + (\" ...\" if len(shared) > limit else \"\")\n",
    "\n",
    "def cupid_finalize_table_simple(diverse_df: pd.DataFrame, user_id: int, k: int = CUPID_TOP_K, serendipity_n: int = 2) -> pd.DataFrame:\n",
    "    C = diverse_df.copy()\n",
    "    C[\"user_id\"] = C[\"user_id\"].astype(int)\n",
    "\n",
    "    # main picks\n",
    "    main_n = max(0, k - serendipity_n)\n",
    "    main_df = C.sort_values(\"cupid_final\", ascending=False).head(main_n).copy()\n",
    "    main_df[\"slot\"] = \"matched\"\n",
    "\n",
    "    # serendipity from remaining (already hard‑filtered earlier)\n",
    "    remaining = C[~C[\"user_id\"].isin(main_df[\"user_id\"])].copy()\n",
    "    u_kw = user_kw_set(user_id)\n",
    "    remaining[\"shared_cnt\"] = remaining[\"kw_set\"].apply(lambda s: len(u_kw & s))\n",
    "    ser_pool = remaining[(remaining.get(\"recency_norm\", 0) > 0.6) & (remaining[\"shared_cnt\"] >= 1)]\n",
    "    if len(ser_pool) < serendipity_n:\n",
    "        ser_pool = pd.concat([ser_pool, remaining]).drop_duplicates(\"user_id\")\n",
    "    ser_df = ser_pool.sample(n=min(serendipity_n, len(ser_pool)), random_state=42).copy()\n",
    "    ser_df[\"slot\"] = \"suggested\"\n",
    "\n",
    "    # combine\n",
    "    final = pd.concat([main_df, ser_df], ignore_index=True).drop_duplicates(\"user_id\")\n",
    "\n",
    "    # drop conflicting cols before merge so we keep master values\n",
    "    for col in [\"age\",\"sex\",\"location\",\"job\",\"religion\",\"bio_text\"]:\n",
    "        if col in final.columns:\n",
    "            final = final.drop(columns=[col])\n",
    "\n",
    "    # enrich from master df\n",
    "    enrich = df[[\"user_id\",\"age\",\"sex\",\"location\",\"job\",\"religion\",\"bio_text\"]].copy()\n",
    "    enrich[\"user_id\"] = enrich[\"user_id\"].astype(int)\n",
    "    final = final.merge(enrich, on=\"user_id\", how=\"left\")\n",
    "\n",
    "    # shared interests column\n",
    "    final[\"shared_interests\"] = final[\"kw_set\"].apply(lambda s: shared_kw_str(u_kw, s))\n",
    "\n",
    "    # pick columns + order\n",
    "    cols = [\"user_id\",\"cupid_final\",\"slot\",\"age\",\"sex\",\"location\",\"job\",\"religion\",\"shared_interests\"]\n",
    "    for c in cols:\n",
    "        if c not in final.columns:\n",
    "            final[c] = np.nan\n",
    "    return final[cols].sort_values([\"slot\",\"cupid_final\"], ascending=[True, False]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46dbad0f-3946-4a4d-a964-1b6a605d5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb610d55-b2af-40db-8c87-216847124bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUPID Score = 0.8910\n",
      "User id = 15046 | age = 36 | sex = m | location = san francisco, california\n",
      "job =  | religion = \n",
      "bio text =\n",
      "grew up near philadelphia. practiced law for a few years before deciding that i wanted to do something more creative. moving to the west coast has exposed me to a ...\n",
      "\n",
      "Generated starters:\n",
      "  Pickup line: Are you a legal document? Because you’ve got all the right clauses to catch my interest.\n",
      "  Question:    What’s one creative project you’ve always wanted to dive into but haven’t yet?\n",
      "  Date idea:   Let’s explore a local art gallery followed by a DIY painting class to unleash our inner creatives!\n",
      "\n",
      "CUPID Score = 0.8547\n",
      "User id = 18838 | age = 29 | sex = m | location = san francisco, california\n",
      "job =  | religion = \n",
      "bio text =\n",
      "i love to have fun -- this usually happens while having great discussions, watching sports, playing video games, exercising, reading books, watching movies, and many other things i find fascinating. ...\n",
      "\n",
      "Generated starters:\n",
      "  Pickup line: Are you a magician? Because whenever I look at you, everyone else disappears.\n",
      "  Question:    What's the last book or movie that really made you think?\n",
      "  Date idea:   How about a cozy game night where we can challenge each other with our favorite video games and share some snacks?\n",
      "\n",
      "CUPID Score = 0.8332\n",
      "User id = 3717 | age = 37 | sex = m | location = palo alto, california\n",
      "job =  | religion = \n",
      "bio text =\n",
      "people tell me that i'm am easy going but motivated. you can find me at a party in the mountains one day and motocrossing the next. my hobbies are dirt ...\n",
      "\n",
      "Generated starters:\n",
      "  Pickup line: Are you a mountain trail? Because I can't help but get lost in your adventures.\n",
      "  Question:    What's the most thrilling ride you've ever had on a motocross bike?\n",
      "  Date idea:   How about we hit the trails for a dirt bike ride followed by a cozy bonfire under the stars?\n"
     ]
    }
   ],
   "source": [
    "# ==== CUPID: pickup lines + question + date idea (API only) ====\n",
    "API_KEY = \"sk-proj-\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def truncate_bio(bio: str, max_words: int = 30) -> str:\n",
    "    \"\"\"Return the first max_words words of bio (with ellipsis if longer).\"\"\"\n",
    "    words = str(bio).split()\n",
    "    return \" \".join(words[:max_words]) + (\" ...\" if len(words) > max_words else \"\")\n",
    "\n",
    "def cupid_print_starters(user_id: int, k: int = 3, model: str = \"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    For the top-k CUPID matches:\n",
    "      - Show CUPID score + profile details\n",
    "      - Generate 1 pickup line + 1 playful question + 1 date idea\n",
    "    Assumes `final_slate` already exists from the CUPID pipeline.\n",
    "    \"\"\"\n",
    "    # grab top-k matches from your CUPID final slate\n",
    "    ranked = final_slate.sort_values(\"cupid_final\", ascending=False).head(k).copy()\n",
    "\n",
    "    for _, r in ranked.iterrows():\n",
    "        uid   = int(r[\"user_id\"])\n",
    "        score = float(r[\"cupid_final\"])\n",
    "        age   = r.get(\"age\", \"\")\n",
    "        sex   = r.get(\"sex\", \"\")\n",
    "        loc   = r.get(\"location\", \"\")\n",
    "        job   = r.get(\"job\", \"\")\n",
    "        rel   = r.get(\"religion\", \"\")\n",
    "        # safe bio fetch + truncate\n",
    "        bio_series = df.loc[df[\"user_id\"] == uid, \"bio_text\"]\n",
    "        bio_full = bio_series.iloc[0] if len(bio_series) else \"\"\n",
    "        bio = truncate_bio(bio_full, max_words=30)\n",
    "\n",
    "        # API call to GPT\n",
    "        prompt = (\n",
    "            f\"Profile bio:\\n{bio}\\n\\n\"\n",
    "            \"Write exactly three lines:\\n\"\n",
    "            \"PICKUP: one playful pickup line (no emojis)\\n\"\n",
    "            \"QUESTION: one light, open question (no emojis)\\n\"\n",
    "            \"DATE: one fun first-date idea tailored to their mutual interests\\n\"\n",
    "        )\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "            temperature=0.8,\n",
    "        )\n",
    "        text = resp.choices[0].message.content.strip().splitlines()\n",
    "\n",
    "        # extract three parts\n",
    "        pickup = next((ln.split(\":\",1)[1].strip() for ln in text if ln.upper().startswith(\"PICKUP:\")), \"\")\n",
    "        question = next((ln.split(\":\",1)[1].strip() for ln in text if ln.upper().startswith(\"QUESTION:\")), \"\")\n",
    "        date_idea = next((ln.split(\":\",1)[1].strip() for ln in text if ln.upper().startswith(\"DATE:\")), \"\")\n",
    "\n",
    "        # formatted printout\n",
    "        print(f\"\\nCUPID Score = {score:.4f}\")\n",
    "        print(f\"User id = {uid} | age = {age} | sex = {sex} | location = {loc}\")\n",
    "        print(f\"job = {job} | religion = {rel}\")\n",
    "        print(\"bio text =\")\n",
    "        print(bio if bio else \"(no bio)\")\n",
    "        print(\"\\nGenerated starters:\")\n",
    "        print(f\"  Pickup line: {pickup if pickup else '(n/a)'}\")\n",
    "        print(f\"  Question:    {question if question else '(n/a)'}\")\n",
    "        print(f\"  Date idea:   {date_idea if date_idea else '(n/a)'}\")\n",
    "\n",
    "# run (top 3 only to limit API usage)\n",
    "cupid_print_starters(user_id=u, k=3, model=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77d37e5f-5e7b-452b-be3a-3fd4e6b2fa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cupid_final</th>\n",
       "      <th>slot</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>location</th>\n",
       "      <th>job</th>\n",
       "      <th>religion</th>\n",
       "      <th>shared_interests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>0.819688</td>\n",
       "      <td>matched</td>\n",
       "      <td>43</td>\n",
       "      <td>m</td>\n",
       "      <td>san mateo, california</td>\n",
       "      <td>executive / management</td>\n",
       "      <td>christianity</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44725</td>\n",
       "      <td>0.813595</td>\n",
       "      <td>matched</td>\n",
       "      <td>54</td>\n",
       "      <td>m</td>\n",
       "      <td>alameda, california</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>catholicism</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49783</td>\n",
       "      <td>0.813094</td>\n",
       "      <td>matched</td>\n",
       "      <td>42</td>\n",
       "      <td>m</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>banking / financial / real estate</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11636</td>\n",
       "      <td>0.799925</td>\n",
       "      <td>matched</td>\n",
       "      <td>63</td>\n",
       "      <td>m</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>political / government</td>\n",
       "      <td>atheism</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33493</td>\n",
       "      <td>0.796318</td>\n",
       "      <td>matched</td>\n",
       "      <td>36</td>\n",
       "      <td>m</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>other</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>29371</td>\n",
       "      <td>0.658902</td>\n",
       "      <td>suggested</td>\n",
       "      <td>31</td>\n",
       "      <td>m</td>\n",
       "      <td>vallejo, california</td>\n",
       "      <td>education / academia</td>\n",
       "      <td>atheism and laughing about it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>33773</td>\n",
       "      <td>0.658517</td>\n",
       "      <td>suggested</td>\n",
       "      <td>33</td>\n",
       "      <td>m</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>executive / management</td>\n",
       "      <td>agnosticism and laughing about it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>55125</td>\n",
       "      <td>0.658246</td>\n",
       "      <td>suggested</td>\n",
       "      <td>33</td>\n",
       "      <td>m</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>atheism and very serious about it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33399</td>\n",
       "      <td>0.658234</td>\n",
       "      <td>suggested</td>\n",
       "      <td>31</td>\n",
       "      <td>m</td>\n",
       "      <td>pacifica, california</td>\n",
       "      <td>computer / hardware / software</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>34591</td>\n",
       "      <td>0.658052</td>\n",
       "      <td>suggested</td>\n",
       "      <td>28</td>\n",
       "      <td>m</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>other</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  cupid_final       slot  age sex                   location  \\\n",
       "0     20973     0.819688    matched   43   m      san mateo, california   \n",
       "1     44725     0.813595    matched   54   m        alameda, california   \n",
       "2     49783     0.813094    matched   42   m        oakland, california   \n",
       "3     11636     0.799925    matched   63   m       berkeley, california   \n",
       "4     33493     0.796318    matched   36   m  san francisco, california   \n",
       "..      ...          ...        ...  ...  ..                        ...   \n",
       "95    29371     0.658902  suggested   31   m        vallejo, california   \n",
       "96    33773     0.658517  suggested   33   m  san francisco, california   \n",
       "97    55125     0.658246  suggested   33   m  san francisco, california   \n",
       "98    33399     0.658234  suggested   31   m       pacifica, california   \n",
       "99    34591     0.658052  suggested   28   m  san francisco, california   \n",
       "\n",
       "                                  job  \\\n",
       "0              executive / management   \n",
       "1                   medicine / health   \n",
       "2   banking / financial / real estate   \n",
       "3              political / government   \n",
       "4                               other   \n",
       "..                                ...   \n",
       "95               education / academia   \n",
       "96             executive / management   \n",
       "97        artistic / musical / writer   \n",
       "98     computer / hardware / software   \n",
       "99                              other   \n",
       "\n",
       "                                    religion shared_interests  \n",
       "0                               christianity                   \n",
       "1                                catholicism                   \n",
       "2                                        NaN                   \n",
       "3                                    atheism                   \n",
       "4   catholicism but not too serious about it                   \n",
       "..                                       ...              ...  \n",
       "95             atheism and laughing about it                   \n",
       "96         agnosticism and laughing about it                   \n",
       "97         atheism and very serious about it                   \n",
       "98                                       NaN                   \n",
       "99                               agnosticism                   \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "final_table = cupid_finalize_table_simple(diverse_slate, user_id=15, k=100, serendipity_n=20)\n",
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "226b2a9e-7901-4ac0-9cb6-bfee0ba5af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/custom_algo_user_id:15_k100_ser20.parquet and results/custom_algo_user_id:15_k100_ser20.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, json, os\n",
    "from datetime import datetime\n",
    "\n",
    "# ensure folder exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# run the algo\n",
    "final_table = cupid_finalize_table_simple(\n",
    "    diverse_slate, \n",
    "    user_id=15, \n",
    "    k=100, \n",
    "    serendipity_n=20\n",
    ")\n",
    "\n",
    "# standardize + annotate\n",
    "cupid = final_table.reset_index(drop=True).copy()\n",
    "cupid[\"rank\"] = range(1, len(cupid) + 1)\n",
    "cupid[\"app\"]  = \"custom\"\n",
    "\n",
    "# metadata\n",
    "meta = {\n",
    "    \"app\": \"cupid\",\n",
    "    \"user_id\": 15,\n",
    "    \"top_n\": 100,\n",
    "    \"serendipity_n\": 20,\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "}\n",
    "\n",
    "stem = f\"results/custom_algo_user_id:{meta['user_id']}_k{meta['top_n']}_ser{meta['serendipity_n']}\"\n",
    "\n",
    "# save\n",
    "cupid.to_parquet(f\"{stem}.parquet\", index=False)\n",
    "with open(f\"{stem}.json\",\"w\") as f: json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", f\"{stem}.parquet and {stem}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec80afe-1c11-4317-8c3e-ac16a7e90068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
